{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMgSyrwkUjwaW6qX7Wj2P5d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chengeke/AdaLovelaceCorner/blob/master/GermanTrafficSignsClassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KT3u8y652Mvr"
      },
      "outputs": [],
      "source": [
        "\n",
        "# coding: utf-8\n",
        "\n",
        "# # Traffic sign classification with CNNs\n",
        "#\n",
        "# In this notebook, we'll train a convolutional neural network (CNN,\n",
        "# ConvNet) to classify images of traffic signs from The German Traffic\n",
        "# Sign Recognition Benchmark using TensorFlow 2 / Keras. This notebook\n",
        "# is largely based on the blog post [Building powerful image\n",
        "# classification models using very little data]\n",
        "# (https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html)\n",
        "# by Fran√ßois Chollet.\n",
        "#\n",
        "# **Note that using a GPU with this notebook is highly recommended.**\n",
        "#\n",
        "# First, the needed imports.\n",
        "\n",
        "import os\n",
        "import datetime\n",
        "import pathlib\n",
        "\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import applications, optimizers\n",
        "\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "print('Using Tensorflow version: {}, and Keras version: {}.'.format(\n",
        "    tf.__version__, keras.__version__))\n",
        "\n",
        "# # Data\n",
        "#\n",
        "# The training dataset consists of 5535 images of traffic signs of\n",
        "# varying size. There are 43 different types of traffic signs. In\n",
        "# addition, the validation set consists of 999 images.\n",
        "\n",
        "if 'DATADIR' in os.environ:\n",
        "    DATADIR = os.environ['DATADIR']\n",
        "else:\n",
        "    DATADIR = \"/scratch/project_2006678/data/\"\n",
        "\n",
        "print('Using DATADIR', DATADIR)\n",
        "datapath = os.path.join(DATADIR, \"gtsrb/train-5535/\")\n",
        "assert os.path.exists(datapath), \"Data not found at \"+datapath\n",
        "\n",
        "nimages = {'train':5535, 'validation':999}\n",
        "\n",
        "# ### Image paths and labels\n",
        "\n",
        "def get_paths(dataset):\n",
        "    data_root = pathlib.Path(datapath+dataset)\n",
        "    image_paths = list(data_root.glob('*/*'))\n",
        "    image_paths = [str(path) for path in image_paths]\n",
        "    image_count = len(image_paths)\n",
        "    assert image_count == nimages[dataset], \\\n",
        "        \"Found {} images, expected {}\".format(image_count, nimages[dataset])\n",
        "    return image_paths\n",
        "\n",
        "image_paths = dict()\n",
        "image_paths['train'] = get_paths('train')\n",
        "image_paths['validation'] = get_paths('validation')\n",
        "\n",
        "label_names = sorted(item.name for item in\n",
        "                     pathlib.Path(datapath+'train').glob('*/') if\n",
        "                     item.is_dir())\n",
        "label_to_index = dict((name, index) for index, name in enumerate(label_names))\n",
        "\n",
        "def get_labels(dataset):\n",
        "    return [label_to_index[pathlib.Path(path).parent.name]\n",
        "            for path in image_paths[dataset]]\n",
        "\n",
        "image_labels = dict()\n",
        "image_labels['train'] = get_labels('train')\n",
        "image_labels['validation'] = get_labels('validation')\n",
        "\n",
        "# ###Data loading\n",
        "#\n",
        "# We now define a function to load the images. The images are in PPM\n",
        "# format, so we use the PIL library. Also we need to resize the images\n",
        "# to a fixed size (INPUT_IMAGE_SIZE).\n",
        "\n",
        "INPUT_IMAGE_SIZE = [80, 80]\n",
        "\n",
        "def _load_image(path, label):\n",
        "    image = Image.open(path.numpy())\n",
        "    return np.array(image), label\n",
        "\n",
        "def load_image(path, label):\n",
        "    image, label = tf.py_function(_load_image, (path, label),\n",
        "                                  (tf.float32, tf.int32))\n",
        "    image.set_shape([None, None, None])\n",
        "    label.set_shape([])\n",
        "    return tf.image.resize(image, INPUT_IMAGE_SIZE), label\n",
        "\n",
        "# ### TF Datasets\n",
        "#\n",
        "# Let's now define our TF Datasets for training and validation data.\n",
        "\n",
        "BATCH_SIZE = 50\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "    (image_paths['train'], image_labels['train']))\n",
        "train_dataset = train_dataset.map(load_image,\n",
        "                                  num_parallel_calls=tf.data.AUTOTUNE)\n",
        "train_dataset = train_dataset.shuffle(2000).batch(BATCH_SIZE, drop_remainder=True)\n",
        "train_dataset = train_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "validation_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "    (image_paths['validation'], image_labels['validation']))\n",
        "validation_dataset = validation_dataset.map(load_image,\n",
        "                                            num_parallel_calls=tf.data.AUTOTUNE)\n",
        "validation_dataset = validation_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "validation_dataset = validation_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "# ## Reuse a pre-trained CNN\n",
        "#\n",
        "# We now reuse a pretrained network. Here we'll use the [VGG16]\n",
        "# (https://keras.io/applications/#vgg16) network architecture\n",
        "# with weights learned using Imagenet. \n",
        "#\n",
        "# ### Initialization\n",
        "\n",
        "# Due to the small number of training images, a large network will\n",
        "# easily overfit. Therefore, to make the most of our limited number of\n",
        "# training examples, we'll apply random augmentation transformations\n",
        "# (small random crop and contrast adjustment) to them each time we are\n",
        "# looping over them. This way, we \"augment\" our training dataset to\n",
        "# contain more data.\n",
        "#\n",
        "# The augmentation transformations are implemented as preprocessing\n",
        "# layers in Keras. There are various such layers readily available,\n",
        "# see https://keras.io/guides/preprocessing_layers/ for more\n",
        "# information.\n",
        "\n",
        "inputs = keras.Input(shape=INPUT_IMAGE_SIZE+[3])\n",
        "x = layers.Rescaling(scale=1./255)(inputs)\n",
        "\n",
        "x = layers.RandomCrop(75, 75)(x)\n",
        "x = layers.RandomContrast(0.1)(x)\n",
        "\n",
        "# We load the pretrained network, remove the top layers, and\n",
        "# freeze the pre-trained weights.\n",
        "\n",
        "vgg16 = applications.VGG16(weights='imagenet', include_top=False,\n",
        "                           input_tensor=x)\n",
        "for layer in vgg16.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# We then stack our own, randomly initialized layers on top of the\n",
        "# VGG16 network.\n",
        "\n",
        "x = layers.Flatten()(vgg16.output)\n",
        "x = layers.Dense(64, activation='relu')(x)\n",
        "outputs = layers.Dense(43, activation='softmax')(x)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs,\n",
        "                    name=\"gtsrb-vgg16-pretrained\")\n",
        "print(model.summary())\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# ### Learning 1: New layers\n",
        "\n",
        "logdir = os.path.join(os.getcwd(), \"logs\", \"gtsrb-vgg16-\" +\n",
        "                      datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S'))\n",
        "print('TensorBoard log directory:', logdir)\n",
        "os.makedirs(logdir)\n",
        "callbacks = [TensorBoard(log_dir=logdir)]\n",
        "\n",
        "epochs = 20\n",
        "\n",
        "history = model.fit(train_dataset, epochs=epochs,\n",
        "                    validation_data=validation_dataset,\n",
        "                    verbose=2, callbacks=callbacks)\n",
        "\n",
        "fname = \"gtsrb-vgg16-reuse.h5\"\n",
        "print('Saving model to', fname)\n",
        "model.save(fname)\n",
        "\n",
        "# ### Learning 2: Fine-tuning\n",
        "#\n",
        "# Once the top layers have learned some reasonable weights, we can\n",
        "# continue training by unfreezing the last convolution block of VGG16\n",
        "# (`block5`) so that it may adapt to our data. The learning rate\n",
        "# should be smaller than usual.\n",
        "\n",
        "train_layer = False\n",
        "for layer in model.layers:\n",
        "    if layer.name == \"block5_conv1\":\n",
        "        train_layer = True\n",
        "    layer.trainable = train_layer\n",
        "    \n",
        "for i, layer in enumerate(model.layers):\n",
        "    print(i, layer.name, \"trainable:\", layer.trainable)\n",
        "print(model.summary())    \n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(learning_rate=1e-5),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "logdir = os.path.join(os.getcwd(), \"logs\", \"gtsrb-vgg16-finetune-\" +\n",
        "                      datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S'))\n",
        "print('TensorBoard log directory:', logdir)\n",
        "os.makedirs(logdir)\n",
        "callbacks = [TensorBoard(log_dir=logdir)]\n",
        "\n",
        "epochs = 20\n",
        "\n",
        "history = model.fit(train_dataset, epochs=epochs,\n",
        "                    validation_data=validation_dataset,\n",
        "                    verbose=2, callbacks=callbacks)\n",
        "\n",
        "fname = \"gtsrb-vgg16-finetune.h5\"\n",
        "\n",
        "print('Saving model to', fname)\n",
        "model.save(fname)\n"
      ]
    }
  ]
}